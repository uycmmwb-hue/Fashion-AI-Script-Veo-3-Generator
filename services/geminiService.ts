
import { GoogleGenAI, Type, Schema } from "@google/genai";
import { AppConfig, VisionAnalysis, Script, GeneratedVeoData } from "../types";

import { GoogleGenerativeAI } from "@google/generative-ai";
console.log("üëâ Gemini KEY Loaded:", import.process.env.VITE_GEMINI_API_KEY);

const genAI = new GoogleGenerativeAI(import.process.env.VITE_GEMINI_API_KEY);

export default genAI;

// --- Helper: File to Base64 ---
export const fileToGenerativePart = async (file: File): Promise<string> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      const base64String = reader.result as string;
      // Remove data url prefix (e.g. "data:image/jpeg;base64,")
      const base64 = base64String.split(',')[1];
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
};

// --- 1. Vision Analysis ---
export const analyzeProductImage = async (base64Image: string): Promise<VisionAnalysis> => {
  const ai = getAI();
  
  const prompt = `
    Ph√¢n t√≠ch h√¨nh ·∫£nh s·∫£n ph·∫©m th·ªùi trang n√†y ƒë·ªÉ vi·∫øt k·ªãch b·∫£n video marketing.
    Tr√≠ch xu·∫•t c√°c chi ti·∫øt sau d∆∞·ªõi d·∫°ng JSON (Gi√° tr·ªã tr·∫£ v·ªÅ ph·∫£i b·∫±ng Ti·∫øng Vi·ªát):
    - category: Lo·∫°i s·∫£n ph·∫©m (v√≠ d·ª•: V√°y m√πa h√®, Vest c√¥ng s·ªü).
    - color_tone: B·∫£ng m√†u ch·ªß ƒë·∫°o.
    - style: Phong c√°ch th·ªùi trang (v√≠ d·ª•: T·ªëi gi·∫£n, Vintage, ƒê∆∞·ªùng ph·ªë).
    - target_age: ƒê·ªô tu·ªïi kh√°ch h√†ng m·ª•c ti√™u ∆∞·ªõc t√≠nh.
    - brand_tone: Gi·ªçng ƒëi·ªáu th∆∞∆°ng hi·ªáu g·ª£i √Ω (v√≠ d·ª•: Sang tr·ªçng, Vui t∆∞∆°i).
    - usp_highlights: 5 ƒëi·ªÉm b√°n h√†ng ƒë·ªôc nh·∫•t (USP) ho·∫∑c ƒëi·ªÉm nh·∫•n h√¨nh ·∫£nh.
    - tone_scores: M·ªôt m·∫£ng c√°c ƒë·ªëi t∆∞·ª£ng c√≥ 'name' (thu·ªôc t√≠nh nh∆∞ 'Sang tr·ªçng', 'Tho·∫£i m√°i', 'T√°o b·∫°o', 'Thanh l·ªãch', 'Xu h∆∞·ªõng') v√† 'value' (ƒëi·ªÉm s·ªë nguy√™n 0-100).
  `;

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: {
      parts: [
        { inlineData: { mimeType: 'image/jpeg', data: base64Image } },
        { text: prompt }
      ]
    },
    config: {
      responseMimeType: 'application/json',
      responseSchema: {
        type: Type.OBJECT,
        properties: {
          category: { type: Type.STRING },
          color_tone: { type: Type.STRING },
          style: { type: Type.STRING },
          target_age: { type: Type.STRING },
          brand_tone: { type: Type.STRING },
          usp_highlights: { type: Type.ARRAY, items: { type: Type.STRING } },
          tone_scores: {
            type: Type.ARRAY,
            items: {
              type: Type.OBJECT,
              properties: {
                name: { type: Type.STRING },
                value: { type: Type.INTEGER }
              }
            }
          }
        }
      }
    }
  });

  if (!response.text) throw new Error("No analysis result");
  return JSON.parse(response.text) as VisionAnalysis;
};

// --- 2. Generate Scripts ---
export const generateScripts = async (config: AppConfig): Promise<Script[]> => {
  const ai = getAI();
  
  // Logic x·ª≠ l√Ω nghi√™m ng·∫∑t cho y√™u c·∫ßu Kh√¥ng l·ªùi tho·∫°i
  const isNoDialogue = config.videoStyle.includes('Kh√¥ng l·ªùi tho·∫°i');
  
  const strictRequirements = isNoDialogue
    ? `Y√äU C·∫¶U ƒê·∫∂C BI·ªÜT: ƒê√¢y l√† video KH√îNG L·ªúI THO·∫†I (Non-verbal). 
       - Tuy·ªát ƒë·ªëi KH√îNG vi·∫øt l·ªùi tho·∫°i cho nh√¢n v·∫≠t. 
       - Tr∆∞·ªùng 'dialogue_or_text' CH·ªà ƒê∆Ø·ª¢C ch·ª©a n·ªôi dung ch·ªØ hi·ªÉn th·ªã (Text Overlay) ho·∫∑c ghi ch√∫ v·ªÅ √¢m nh·∫°c/√¢m thanh.
       - T·∫≠p trung m√¥ t·∫£ h√†nh ƒë·ªông v√† bi·ªÉu c·∫£m.`
    : `Y√äU C·∫¶U: Vi·∫øt l·ªùi tho·∫°i t·ª± nhi√™n, h·∫•p d·∫´n, ph√π h·ª£p v·ªõi gi·ªçng ƒë·ªçc ${config.accent}.`;

  const prompt = `
    ƒê√≥ng vai m·ªôt ƒê·∫°o di·ªÖn Video Th·ªùi trang chuy√™n nghi·ªáp.
    T·∫°o 5 k·ªãch b·∫£n video 30 gi√¢y kh√°c bi·ªát cho s·∫£n ph·∫©m sau.
    N·ªôi dung k·ªãch b·∫£n ph·∫£i vi·∫øt b·∫±ng Ti·∫øng Vi·ªát (tr·ª´ khi Ng√¥n ng·ªØ ƒë∆∞·ª£c ch·ªçn l√† Ti·∫øng Anh).
    
    S·∫£n ph·∫©m: ${config.productName}
    M√¥ t·∫£: ${config.productDescription}
    D·ªØ li·ªáu ph√¢n t√≠ch Vision: ${JSON.stringify(config.visionData)}
    
    C√†i ƒë·∫∑t:
    - Phong c√°ch: ${config.videoStyle}
    - Lo·∫°i: ${config.videoType}
    - Ng√¥n ng·ªØ: ${config.language}
    - Gi·ªçng ƒë·ªçc: ${config.accent}
    
    Y√äU C·∫¶U B·∫ÆT BU·ªòC (TU√ÇN TH·ª¶ TUY·ªÜT ƒê·ªêI):
    1. S·ªê L∆Ø·ª¢NG C·∫¢NH: M·ªói k·ªãch b·∫£n ph·∫£i c√≥ ƒê√öNG 3 C·∫¢NH (SCENES). Kh√¥ng ƒë∆∞·ª£c vi·∫øt nhi·ªÅu h∆°n hay √≠t h∆°n 3 c·∫£nh.
    2. ${strictRequirements}
    3. T·ªïng th·ªùi l∆∞·ª£ng x·∫•p x·ªâ 30 gi√¢y.
    4. C√°c k·ªãch b·∫£n n√™n kh√°c nhau v·ªÅ g√≥c ƒë·ªô (v√≠ d·ª•: m·ªôt c√°i thi√™n v·ªÅ c·∫£m x√∫c, m·ªôt c√°i nh·ªãp ƒë·ªô nhanh, m·ªôt c√°i t·∫≠p trung v√†o t√≠nh nƒÉng).
    
    Tr·∫£ v·ªÅ m·ªôt m·∫£ng JSON g·ªìm 5 k·ªãch b·∫£n.
  `;

  const schema: Schema = {
    type: Type.ARRAY,
    items: {
      type: Type.OBJECT,
      properties: {
        id: { type: Type.STRING },
        title: { type: Type.STRING },
        hook: { type: Type.STRING },
        rationale: { type: Type.STRING, description: "L√Ω do t·∫°i sao k·ªãch b·∫£n n√†y hi·ªáu qu·∫£" },
        benefits_highlighted: { type: Type.ARRAY, items: { type: Type.STRING } },
        cta_overlay: { type: Type.STRING },
        cta_voice: { type: Type.STRING },
        scenes: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              time: { type: Type.STRING },
              action: { type: Type.STRING },
              dialogue_or_text: { type: Type.STRING, description: isNoDialogue ? "Ch·ªâ ch·ªØ hi·ªÉn th·ªã (Overlay) ho·∫∑c √Çm nh·∫°c" : "L·ªùi tho·∫°i ho·∫∑c ch·ªØ hi·ªÉn th·ªã" },
              camera_angle: { type: Type.STRING },
              visual_prompt: { type: Type.STRING, description: "M√¥ t·∫£ h√¨nh ·∫£nh ng·∫Øn g·ªçn cho AI t·∫°o video (Vi·∫øt b·∫±ng Ti·∫øng Anh ƒë·ªÉ t·ªëi ∆∞u cho Veo)" },
              music: { type: Type.STRING }
            }
          }
        }
      }
    }
  };

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: prompt,
    config: {
      responseMimeType: 'application/json',
      responseSchema: schema
    }
  });

  if (!response.text) throw new Error("Failed to generate scripts");
  return JSON.parse(response.text) as Script[];
};

// --- 3. Generate Veo-3 Prompt ---
export const generateVeoPrompt = async (script: Script, config: AppConfig): Promise<GeneratedVeoData> => {
  const ai = getAI();
  
  const prompt = `
    D·ª±a tr√™n k·ªãch b·∫£n video ƒë√£ ch·ªçn g·ªìm ${script.scenes.length} c·∫£nh, h√£y t·∫°o ${script.scenes.length} JSON prompt ri√™ng bi·ªát t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng ph√¢n c·∫£nh (scene) ƒë·ªÉ t·∫°o video b·∫±ng model Veo-3.
    N·ªôi dung trong JSON (description, style, characters, etc.) ph·∫£i vi·∫øt b·∫±ng TI·∫æNG ANH (English) chu·∫©n.
    
    Th√¥ng tin ƒë·∫ßu v√†o:
    - Ti√™u ƒë·ªÅ k·ªãch b·∫£n: ${script.title}
    - S·∫£n ph·∫©m: ${config.productName}
    - Vision Data: ${JSON.stringify(config.visionData)}
    - Script Content: ${JSON.stringify(script)}
    
    Y√äU C·∫¶U T·ªêI ∆ØU H√ìA CH·∫§T L∆Ø·ª¢NG (N√ÇNG CAO):
    ƒê·ªÉ t·∫°o ra video ch·∫•t l∆∞·ª£ng cao nh·∫•t, h√£y t·ª± ƒë·ªông th√™m c√°c chi ti·∫øt chuy√™n nghi·ªáp sau v√†o prompt (Enrichment) ngay c·∫£ khi k·ªãch b·∫£n g·ªëc kh√¥ng ghi r√µ:
    1. CAMERA: S·ª≠ d·ª•ng ng√¥n ng·ªØ ƒëi·ªán ·∫£nh c·ª• th·ªÉ (v√≠ d·ª•: "Slow cinematic dolly-in", "Low-angle tracking shot", "Smooth pan revealing details", "Rack focus from blurry foreground"). Tr√°nh c√°c g√≥c m√°y tƒ©nh nh√†m ch√°n.
    2. LIGHTING: M√¥ t·∫£ chi ti·∫øt h∆∞·ªõng v√† ch·∫•t l∆∞·ª£ng √°nh s√°ng (v√≠ d·ª•: "Soft volumetric lighting", "Golden hour rim-light emphasizing texture", "Studio fashion lighting with softbox", "Moody chiaroscuro").
    3. MOTION: M√¥ t·∫£ chuy·ªÉn ƒë·ªông vi m√¥ (micro-movements) ƒë·ªÉ nh√¢n v·∫≠t s·ªëng ƒë·ªông (v√≠ d·ª•: "fingers gently tracing the fabric", "subtle shift in weight", "hair blowing softly in wind", "eyes glancing confidently").
    4. STYLE: Th√™m c√°c t·ª´ kh√≥a ch·∫•t l∆∞·ª£ng cao (v√≠ d·ª•: "8k", "photorealistic", "highly detailed texture", "fashion magazine editorial look", "shot on Arri Alexa").
    
    QUAN TR·ªåNG: 
    1. Tr·∫£ v·ªÅ m·∫£ng "scenePrompts" ch·ª©a ƒë√∫ng ${script.scenes.length} ƒë·ªëi t∆∞·ª£ng JSON.
    2. M·ªói ƒë·ªëi t∆∞·ª£ng JSON t∆∞∆°ng ·ª©ng v·ªõi 1 c·∫£nh trong k·ªãch b·∫£n theo ƒë√∫ng th·ª© t·ª±.
    3. C·∫•u tr√∫c m·ªói JSON ph·∫£i ch√≠nh x√°c nh∆∞ sau:
    
    {
      "description": "M√¥ t·∫£ chi ti·∫øt ph√¢n c·∫£nh...",
      "style": "Elegant, contemporary fashion editorial...",
      "camera": "G√≥c m√°y v√† chuy·ªÉn ƒë·ªông c·ªßa c·∫£nh n√†y...",
      "lighting": "√Ånh s√°ng...",
      "environment": "B·ªëi c·∫£nh...",
      "characters": [ ... ],
      "motion": "H√†nh ƒë·ªông c·ª• th·ªÉ trong c·∫£nh n√†y...",
      "dialogue": [ ... ],
      "ending": "K·∫øt th√∫c c·ªßa c·∫£nh n√†y...",
      "text": "vƒÉn b·∫£n hi·ªÉn th·ªã",
      "keywords": [ ... ],
      "aspect_ratio": "9:16"
    }

    Ngo√†i ra, t·∫°o th√™m c√°c t√†i s·∫£n marketing (adsCaption, hashtags, ctaVariations) b·∫±ng Ti·∫øng Vi·ªát.
  `;

  // Schema definition for a single Veo Prompt Structure to be reused in array
  const veoPromptSchema: Schema = {
    type: Type.OBJECT,
    properties: {
      description: { type: Type.STRING },
      style: { type: Type.STRING },
      camera: { type: Type.STRING },
      lighting: { type: Type.STRING },
      environment: { type: Type.STRING },
      characters: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            name: { type: Type.STRING },
            age: { type: Type.STRING },
            gender: { type: Type.STRING },
            ethnicity: { type: Type.STRING },
            appearance: {
              type: Type.OBJECT,
              properties: {
                hair: { type: Type.STRING },
                expression: { type: Type.STRING },
                outfit: { type: Type.STRING }
              }
            }
          }
        }
      },
      motion: { type: Type.STRING },
      dialogue: { type: Type.ARRAY, items: { type: Type.STRING } },
      ending: { type: Type.STRING },
      text: { type: Type.STRING },
      keywords: { type: Type.ARRAY, items: { type: Type.STRING } },
      aspect_ratio: { type: Type.STRING }
    }
  };

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      scenePrompts: {
        type: Type.ARRAY,
        items: veoPromptSchema
      },
      adsCaption: { type: Type.STRING },
      hashtags: { type: Type.ARRAY, items: { type: Type.STRING } },
      ctaVariations: { type: Type.ARRAY, items: { type: Type.STRING } }
    }
  };

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: prompt,
    config: {
      responseMimeType: 'application/json',
      responseSchema: schema
    }
  });

  if (!response.text) throw new Error("Failed to generate Veo prompt");
  return JSON.parse(response.text) as GeneratedVeoData;
};
